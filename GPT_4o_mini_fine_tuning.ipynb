{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DTMZdMHArdA3"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {role: \"system\", \"content\":\"You are a great philosopher.\"}\n",
        "        {role: \"user\", \"content\":\"What is the meaning of life?\"}\n",
        "    ]\n",
        ")\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "id": "6rOaIWNbrrNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "file_path = \"Reddit_Title.csv\"\n",
        "data = pd.read_csv(file_path, sep=\";\")\n",
        "\n",
        "data_cleaned = data[['title','label']].head(200)\n",
        "\n",
        "label_mapping = {0: \"non-stress\", 1:\"stress\"}\n",
        "data_cleaned['label'] = data_cleaned['label'].map(label_mapping)\n",
        "\n",
        "train_data, validation_data = train_test_split(data_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "def save_to_jsonl(data, output_file_path):\n",
        "  jsonl_data = []\n",
        "  for index, row in data.iterrows():\n",
        "    jsonl_data.append({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\":\"Given a social media post, classify whether it indicates 'stress' or 'non-stress'.\"},\n",
        "            {\"role\": \"user\", \"content\":row['title']},\n",
        "            {\"role\": \"assistant\", \"content\":f\"\\\"{row['label']}\\\"\"}\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    with open(output_file_path, 'w') as f:\n",
        "      for item in jsonl_data:\n",
        "        f.write(json.dumps(item)+'\\n')\n",
        "\n",
        "train_output_file_path = 'stress_detection_train.jsonl'\n",
        "validation_output_file_path = 'stress_detection_validation.jsonl'\n",
        "\n",
        "save_to_jsonl(train_data, train_output_file_path)\n",
        "save_to_jsonl(validation_data, validation_output_file_path)\n",
        "\n",
        "print(f\"Training dataset save to {train_output_file_path}\")\n",
        "print(f\"Validation dataset save to {validation_output_file_path}\")"
      ],
      "metadata": {
        "id": "c-G3hAlfst8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = client.files.create(\n",
        "    file=open(train_output_file_path, \"rb\")\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_output_file_path, \"rb\")\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "wZt57Dbist2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = client.fine_tuning.jobs.create(\n",
        "    training_file = train_file.id,\n",
        "    validation_file = valid_file.id,\n",
        "    model=\"gpt-4o-mini-2024-07-18\",\n",
        "    hyperparameters={\n",
        "    \"n_epochs\": 3,\n",
        "    \"batch_size\": 3,\n",
        "    \"learning_rate_multiplier\": 0.3\n",
        "  }\n",
        ")\n",
        "\n",
        "job_id = model.id\n",
        "status = model.status\n",
        "\n",
        "print(f'Fine-tuning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {model}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "id": "Za64lI0dstyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgQD0kPxstt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_UtuIhAstql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLaEFLzIstnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-6wEOOnstky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KE-1t2hesth4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLXTiFFYstfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0bQdmT9stcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}